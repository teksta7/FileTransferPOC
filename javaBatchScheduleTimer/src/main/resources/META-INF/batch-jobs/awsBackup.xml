<job id="awsBackup" xmlns="http://xmlns.jcp.org/xml/ns/javaee" version="1.0"> <!-- Batch Job name -->

  <listeners>
    <listener ref="org.jberet.schedule.SchedulingJobListener">
      <properties>

        <!-- all properties for this listener are optional, and they are included
        for illustration purpose
        -->
        <property name="initialDelay"  value="1"/>

        <!--
        max
         number of schedules
        -->
        <property name="maxSchedules" value="20"/>

        <!--
        only when current job execution status is FAILED, STOPPED or COMPLETED,
        will the next execution be scheduled
        -->
        <property name="onBatchStatus" value="FAILED, STOPPED, COMPLETED"/>

        <!--
        at the end of a failed or stopped job executions, whether to restart that job execution,
        or start a new job execution
        -->
        <property name="restartFailedStopped" value="true"/>

        <!--
        whether the job schedule should be persistent.
        -->
        <property name="persistent" value="true"/>
      </properties>
    </listener>
  </listeners>


  <step id="uploadToS3"> <!-- Step name - can be N number of steps to trigger multiple types of logic/functions-->
    <!-- to iterate through Reader and processor for the amount of "item-count" before doing the same with writer in a chunk step -->
    <chunk item-count="1">
      <reader ref="com.jake.javaBatch.DownloadFolderReader"/> <!--Read data from somewhere to make availble to batch runtime-->
      <processor ref="com.jake.javaBatch.ReadLatestFileProcessor"/> <!-- process data from batch runtime -->
      <writer ref="com.jake.javaBatch.UploadS3Writer"/> <!-- write data generated from processor -->
    </chunk>
  </step>
</job>
